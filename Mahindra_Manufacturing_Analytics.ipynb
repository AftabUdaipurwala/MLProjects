{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mahindra Manufacturing Analytics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGyP+Q6ZzZcdFUDJOTiELY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AftabUdaipurwala/MLProjects/blob/main/Mahindra_Manufacturing_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OftOZvF2O1V"
      },
      "source": [
        "# ***Import Python Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ouLN1kza-g"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize']=(20,10)\n",
        "from scipy import stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwIVvlK014Un"
      },
      "source": [
        "# ***Mount Google Drive to Load Data***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp20MtNRzRFs"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lGvvxCNzXIm"
      },
      "source": [
        "!ls '/content/drive/MyDrive/MahindraManufacturingAnalytics' # listing all the contents in the drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg7oLA4K2cbT"
      },
      "source": [
        "# ***Load Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPG0g_SOzdUS"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/MahindraManufacturingAnalytics/ManufacturingAnalytics.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ39BAGK-7Cx"
      },
      "source": [
        "df= pd.DataFrame(df, index = range(0,9999))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqclPklT2pBa"
      },
      "source": [
        "# ***Read and Understand Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA8DkfO222Pa"
      },
      "source": [
        "df.shape # checking shape of the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz0qH4J747iI"
      },
      "source": [
        "df.describe()\n",
        "#''' Here we can clearly see that there are lot of outliers in each of thte variable,\n",
        "# eg just check process temp, its min is 0, max is 11000 but 25th n 75th percentile is very narrow 308-311'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95_nQw3J82GA"
      },
      "source": [
        "df.isnull().sum(axis = 0) ## Checking which all columns have null values. Here Couple of points to be noted are 1. the failure type missing values are 4 all togather"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTNE0sqN9fve"
      },
      "source": [
        "df1=df[df.isnull().any(axis='columns')] # If we take subset of only missing values rows and then investigate\n",
        "df1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJeNPSb9-GK4"
      },
      "source": [
        "df1.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXQheBDg3_ph"
      },
      "source": [
        "pd.crosstab(df1['Machine failure'],df1['RNF']) \n",
        "# So here we can safely say if we remove all these missing values it wont have any big impact on the y variable as only 1 of 50 values is a downtime record. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbpIGO614AQb"
      },
      "source": [
        "df.plot.hist(subplots=True, legend=True, layout=(4, 4)) # checking distribution of each variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG06ezBd6Qp0"
      },
      "source": [
        "# checking if we have any unique values in each variable or is everything only a single point data?\n",
        "df2 = df.dropna(axis=0)\n",
        "df2= df2.drop(['ID'],axis=1)\n",
        "col_names = df2.columns\n",
        "\n",
        "for i in col_names:\n",
        "  x = len(df2[i].unique())\n",
        "  print('Column Name is',i,'& Count of Unique values is ',x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kmatdo_KHD8"
      },
      "source": [
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0E-2t878dVM"
      },
      "source": [
        "# creating a function to check values between 2 quantiles\n",
        "\n",
        "def check_range(df, col):\n",
        "  q_low = df[col].quantile(0.25)\n",
        "  q_hi  = df[col].quantile(0.75)    \n",
        "  print(col,\"qhi\",q_hi,'qlow',q_low)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1n6dkU39K78"
      },
      "source": [
        "df3 = df2.drop(['Type','Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis=1)\n",
        "col_names=df3.columns\n",
        "col_names\n",
        "\n",
        "for i in col_names:\n",
        "  check_range(df3,i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-MBpKP3Gtv6"
      },
      "source": [
        "# creating a function to check values between 2 quantiles\n",
        "\n",
        "def drop_numerical_outliers(df, col):\n",
        "  q_low = df[col].quantile(0.01)\n",
        "  q_hi  = df[col].quantile(0.99)    \n",
        "  df= df[(df[col] < q_hi) & (df[col] > q_low)]\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mYaMPLbICdg"
      },
      "source": [
        "df4= df2.copy()\n",
        "df4 = drop_numerical_outliers(df4,'Air temperature [K]')\n",
        "df4 = drop_numerical_outliers(df4,'Process temperature [K]')\n",
        "df4 = drop_numerical_outliers(df4,'Rotational speed [rpm]')\n",
        "df4 = drop_numerical_outliers(df4,'Torque [Nm]')\n",
        "df4 = drop_numerical_outliers(df4,'Tool wear [min]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL63mn4UCBqA"
      },
      "source": [
        "df4.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgaKe9rxIb1w"
      },
      "source": [
        "df4.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfDQf1SpIjxg"
      },
      "source": [
        "df4.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Cq2Et3MkzD"
      },
      "source": [
        "df5=df4[df4.isnull().any(axis='columns')] # If we take subset of only missing values rows and then investigate\n",
        "df5.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tufq5oM3R1"
      },
      "source": [
        "pd.crosstab(df4['Machine failure'],df4['TWF'])  # Here we can see that if we try to remove outliers a lot of downtime data is lost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg8g44S1jMgo"
      },
      "source": [
        "df4.plot.hist(subplots=True, legend=True, layout=(4, 4)) # checking distribution of each variable"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}